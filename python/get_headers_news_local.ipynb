{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9965e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import functions_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07eba9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_articles():\n",
    "    with open('./get_headers_news_local.json', 'r') as json_file:\n",
    "        websites = json.load(json_file)\n",
    "\n",
    "    # サイト毎に見出しを見に行き、前回との差分を見る\n",
    "    for site in websites:\n",
    "        response =requests.get(site[\"url\"])\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        headlines = soup.select(site[\"selector\"])\n",
    "\n",
    "        # 前回の見出しを保存しておく\n",
    "        site[\"get_title_before\"] = site[\"get_title\"]\n",
    "        # 取得した見出しを保存\n",
    "        site[\"get_title\"] = headlines[0].text.strip()\n",
    "\n",
    "        # 結果を表示\n",
    "        print(\n",
    "            site[\"head\"] +\n",
    "            \"\\nNew title\\n\" +\n",
    "            str(site[\"get_title\"]) + \n",
    "            \"\\nBefore title\\n\" +\n",
    "            str(site[\"get_title_before\"])\n",
    "        )\n",
    "\n",
    "        # 差分のが出たかを見て、値として保存\n",
    "        if site[\"get_title_before\"] != site[\"get_title\"]:\n",
    "            print(\"Update\\n\")\n",
    "            site[\"update\"] = True\n",
    "        else:\n",
    "            print(\"No update\\n\")        \n",
    "            site[\"update\"] = False\n",
    "\n",
    "    # 処理の結果を保存\n",
    "    with open(\"./get_headers_news_local.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(websites, json_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # スクレイピングの結果から、アップデートがあったものだけ配列に追加\n",
    "    updates = []\n",
    "    for web in websites:\n",
    "        if web[\"update\"] == True:\n",
    "            updates.append(web)\n",
    "\n",
    "    # 一つ以上アップデートがある場合、ファイルを上書きして保存\n",
    "    if 0 < len(updates):\n",
    "        print(\"get updates\")\n",
    "        japan_tz = pytz.timezone('Asia/Tokyo')\n",
    "        current_time_japan = datetime.now(japan_tz)\n",
    "        formatted_time = current_time_japan.strftime('%Y/%m/%d %H:%M')\n",
    "\n",
    "        new_object = {\n",
    "            \"date\": formatted_time,\n",
    "            \"updates\": updates\n",
    "        }\n",
    "\n",
    "        # 現状を読み込んで変数に格納\n",
    "        with open (\"update.json\", \"r\") as update:\n",
    "            update_json = json.load(update)\n",
    "            update_json.append(new_object)\n",
    "\n",
    "        # 更新分のオブジェクトを配列を追加して、jsonファイルとして保存\n",
    "        with open (\"get_headers_news_local_update.json\", \"w\") as update:\n",
    "            json.dump(update_json, update, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # フロントエンド用にも保存する\n",
    "        with open (\"../docs/data/get_headers_news_local_update.json\", \"w\") as update:\n",
    "            json.dump(update_json, update, ensure_ascii=False, indent=4)\n",
    "        print(update_json[len(update_json)-1])\n",
    "    else:\n",
    "        print(\"no update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日経電子版 速報\n",
      "New title\n",
      "東証10時　下げ幅拡大　一時200円超安　円一段高で\n",
      "Before title\n",
      "育児時短勤務、賃金の1割給付を検討　2歳未満対象\n",
      "Update\n",
      "\n",
      "NHKニュース 速報・新着一覧\n",
      "New title\n",
      "【随時更新】ガザで拘束12人解放 収監のパレスチナ人30人釈放\n",
      "Before title\n",
      "中国 李強首相 半導体などの輸出規制強めるアメリカけん制\n",
      "Update\n",
      "\n",
      "Yahoo!ニュース 速報\n",
      "New title\n",
      "【16日ぶりの救出】インドで建設中のトンネルが崩落、作業員41人が閉じ込められていた事故　全員が救出「健康状態は良好」\n",
      "Before title\n",
      "戦闘休止を2日間延長へ　国連機関の責任者「必要なのは長期の休戦」\n",
      "Update\n",
      "\n",
      "get updates\n",
      "{'date': '2023/11/29 10:14', 'updates': [{'head': '日経電子版 速報', 'media': 'NIKKEI', 'url': 'https://www.nikkei.com/news/category/', 'selector': '#CONTENTS_MAIN > div:nth-child(1) > h3 > a > span', 'get_title': '東証10時\\u3000下げ幅拡大\\u3000一時200円超安\\u3000円一段高で', 'get_title_before': '育児時短勤務、賃金の1割給付を検討\\u30002歳未満対象', 'update': True}, {'head': 'NHKニュース 速報・新着一覧', 'media': 'NHK', 'url': 'https://www3.nhk.or.jp/news/catnew.html', 'selector': '#main > article > section > div > ul > li:nth-child(1) > dl > dd > a > em', 'get_title': '【随時更新】ガザで拘束12人解放 収監のパレスチナ人30人釈放', 'get_title_before': '中国 李強首相 半導体などの輸出規制強めるアメリカけん制', 'update': True}, {'head': 'Yahoo!ニュース 速報', 'media': 'Yahoo!', 'url': 'https://news.yahoo.co.jp/flash', 'selector': '#contentsWrap > div:nth-child(3) > div.sc-dMCwnC.lipeMg > div > a > p', 'get_title': '【16日ぶりの救出】インドで建設中のトンネルが崩落、作業員41人が閉じ込められていた事故\\u3000全員が救出「健康状態は良好」', 'get_title_before': '戦闘休止を2日間延長へ\\u3000国連機関の責任者「必要なのは長期の休戦」', 'update': True}]}\n"
     ]
    }
   ],
   "source": [
    "get_articles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
