{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9965e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c03d90",
   "metadata": {},
   "source": [
    "---\n",
    "## watchlistのcsvをjsonに変換する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6acdfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wachlist_json():\n",
    "    df= pd.read_csv('watchlist/watchlist.csv')\n",
    "\n",
    "    # jsonファイルに変換してファイルに保存\n",
    "    json_data = df.to_json(orient='records', force_ascii=False)\n",
    "    with open (\"watchlist/watchlist.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5f023",
   "metadata": {},
   "source": [
    "---\n",
    "## 期待通りスクレイピングできるか試す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fb66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_head(url, selector):\n",
    "    response_test =requests.get(url)\n",
    "    soup_test = BeautifulSoup(response_test.content, 'html.parser')\n",
    "    headline_test = soup_test.select(selector)\n",
    "    print(headline_test)\n",
    "\n",
    "# test_get_head(\n",
    "#     \"https://www3.nhk.or.jp/news/catnew.html\",\n",
    "#     \"#main > article > section > div > ul > li:nth-child(1) > dl > dd > a\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eaf338",
   "metadata": {},
   "source": [
    "---\n",
    "## watchlistの一覧を元に見出しを見に行く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07eba9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日経電子版 速報\n",
      "New title\n",
      "中国不動産の万科、ムーディーズが2段階格下げ\n",
      "Before title\n",
      "中国不動産の万科、ムーディーズが2段階格下げ\n",
      "No update\n",
      "\n",
      "NHKニュース 速報・新着一覧\n",
      "New title\n",
      "J133節 2位マリノス引き分け あすヴィッセル勝てばリーグ優勝\n",
      "Before title\n",
      "中国 6か国の短期滞在 ビザ免除措置実施へ 日本は再開求める\n",
      "Update\n",
      "\n",
      "Yahoo!ニュース 速報\n",
      "New title\n",
      "【フィギュア】宇野昌磨ＳＰ冒頭の「アイ・ラブ・ユーはどんな意味？」　海外メディアが変化球質問\n",
      "Before title\n",
      "「4日間休戦」開始、自宅目指すガザ住民\n",
      "Update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 現状の一覧を開く（リセットする時はwatchlistをひらく）\n",
    "# with open('./watchlist/watchlist.json', 'r') as json_file:\n",
    "with open('./get_headers.json', 'r') as json_file:\n",
    "    websites = json.load(json_file)\n",
    "\n",
    "# サイト毎に見出しを見に行き、前回との差分を見る\n",
    "for site in websites:\n",
    "    response =requests.get(site[\"url\"])\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    headlines = soup.select(site[\"selector\"])\n",
    "    \n",
    "    # 前回の見出しを保存しておく\n",
    "    site[\"get_title_before\"] = site[\"get_title\"]\n",
    "    # 取得した見出しを保存\n",
    "    site[\"get_title\"] = headlines[0].text.strip()\n",
    "\n",
    "    # 結果を表示\n",
    "    print(\n",
    "        site[\"head\"] +\n",
    "        \"\\nNew title\\n\" +\n",
    "        str(site[\"get_title\"]) + \n",
    "        \"\\nBefore title\\n\" +\n",
    "        str(site[\"get_title_before\"])\n",
    "    )\n",
    "\n",
    "    # 差分のが出たかを見て、値として保存\n",
    "    if site[\"get_title_before\"] != site[\"get_title\"]:\n",
    "        print(\"Update\\n\")\n",
    "        site[\"update\"] = True\n",
    "    else:\n",
    "        print(\"No update\\n\")        \n",
    "        site[\"update\"] = False\n",
    "\n",
    "# 処理の結果を保存\n",
    "with open(\"./get_headers.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(websites, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b02b6",
   "metadata": {},
   "source": [
    "---\n",
    "## アップデートがあったものだけ抽出して、jsonの配列に追加して保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42b1412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'date': '2023/11/24 22:32',\n",
       " 'updates': [{'head': 'NHKニュース 速報・新着一覧',\n",
       "   'media': 'NHK',\n",
       "   'url': 'https://www3.nhk.or.jp/news/catnew.html',\n",
       "   'selector': '#main > article > section > div > ul > li:nth-child(1) > dl > dd > a > em',\n",
       "   'get_title': 'J133節 2位マリノス引き分け あすヴィッセル勝てばリーグ優勝',\n",
       "   'get_title_before': '中国 6か国の短期滞在 ビザ免除措置実施へ 日本は再開求める',\n",
       "   'update': True},\n",
       "  {'head': 'Yahoo!ニュース 速報',\n",
       "   'media': 'Yahoo!',\n",
       "   'url': 'https://news.yahoo.co.jp/flash',\n",
       "   'selector': '#contentsWrap > div:nth-child(3) > div.sc-dMCwnC.lipeMg > div > a > p',\n",
       "   'get_title': '【フィギュア】宇野昌磨ＳＰ冒頭の「アイ・ラブ・ユーはどんな意味？」\\u3000海外メディアが変化球質問',\n",
       "   'get_title_before': '「4日間休戦」開始、自宅目指すガザ住民',\n",
       "   'update': True}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# スクレイピングの結果から、アップデートがあったものだけ配列に追加\n",
    "updates = []\n",
    "for web in websites:\n",
    "    if web[\"update\"] == True:\n",
    "        updates.append(web)\n",
    "\n",
    "# 一つ以上アップデートがある場合、ファイルを上書きして保存\n",
    "if 0 < len(updates):\n",
    "    print(\"get updates\")\n",
    "    japan_tz = pytz.timezone('Asia/Tokyo')\n",
    "    current_time_japan = datetime.now(japan_tz)\n",
    "    formatted_time = current_time_japan.strftime('%Y/%m/%d %H:%M')\n",
    "\n",
    "    new_object = {\n",
    "        \"date\": formatted_time,\n",
    "        \"updates\": updates\n",
    "    }\n",
    "\n",
    "    # 現状を読み込んで変数に格納\n",
    "    with open (\"update.json\", \"r\") as update:\n",
    "        update_json = json.load(update)\n",
    "\n",
    "    # 更新分のオブジェクトを配列を追加して、jsonファイルとして保存\n",
    "    with open (\"update.json\", \"w\") as update:\n",
    "        update_json.append(new_object)\n",
    "        json.dump(update_json, update, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    print(\"no update\")\n",
    "\n",
    "update_json[len(update_json)-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
